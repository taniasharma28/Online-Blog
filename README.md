# Online Blog
### DAY 1: 23 febuary 2022 
## INTRODUCTION
Cognizant is an American multinational information technology services and consulting company. It is headquartered in Teaneck, New Jersey, United States.Cognizant Technology Solutions, founded on January 26, 1994 by Kumar Mahadeva & Francisco D'Souza, is an American multinational IT services provider. It also provides consulting and business process outsourcing (BPO) services.

Cognizant had a period of fast growth during the 2000s and became a Fortune 500 company in 2011; as of 2021, it is ranked 185.It is a member of the NASDAQ-100, the S&P 500, the Forbes Global 2000 and the Fortune 500 and is positioned among the top performing and fastest growing companies in the world.

Head Quarters:
- Teaneck, New Jersey, United States

Key People:
- Chairman — John E. Klein

- Chief Executive Officer (CEO) — Francisco D’Souza

Logo:
- Cognizant’s logo consists of two C’s - one vertical and one horizontal. The vertical C in the logo symbolises the equality of its employees while the horizontal C signifies the corporation’s commitment to its customers.

Net Revenue:
- US$ 12.416 billion (2015)

Number of Employees:
- 255,800 (2016)

Official Websites:
- www.cognizant.com

Achievements:
- Cognizant recognised as a Top Provider in the Outsourcing and Consulting categories besides being named as a Customer Satisfaction Leader by CGT.
- Ovum Decision Matrix recognised Cognizant as "Market Leader" in Outsourcing Testing Service Providers.
- Consumer Goods Technology (CGT) awarded Readers’ Choice Award for the ninth consecutive year.
- Forrester Research, Inc. named Cognizant a Leader in Business Intelligence Services.
- Cognizant placed as a Leader by the IDC MarketSpace report.
- Cognizant placed in IDC MarketScape as a Leader in IT and BPO Services.

### Day 2: 24 febuary 2022 
## BASIC CONCEPT OF SOFTWARE TESTING
What is Software Testing?
Software testing is the process of evaluating and verifying that a software product or application does what it is supposed to do. The benefits of testing include preventing bugs, reducing development costs and improving performance.

Why Software Testing is Important?
Software Testing is Important because if there are any bugs or errors in the software, it can be identified early and can be solved before delivery of the software product. Properly tested software product ensures reliability, security and high performance which further results in time saving, cost effectiveness and customer satisfaction.

What are the benefits of Software Testing?
Here are the benefits of using software testing: Cost-Effective: It is one of the important advantages of software testing. Testing any IT project on time helps you to save your money for the long term. In case if the bugs caught in the earlier stage of software testing, it costs less to fix. Security: It is the most vulnerable and sensitive benefit of software testing. People are looking for trusted products. It helps in removing risks and problems earlier. Product quality: It is an essential requirement of any software product. Testing ensures a quality product is delivered to customers. Customer Satisfaction: The main aim of any product is to give satisfaction to their customers. UI/UX Testing ensures the best user experience.

Types of Testing
1. FUNCTIONAL TESTING:
Functional testing checks an application, website, or system to ensure it’s doing exactly what it’s supposed to be doing.

2. NON FUNCTIONAL TESTING:
Non functional testing verifies the readiness of a system according to nonfunctional parameters (performance, accessibility, UX, etc.) which are never addressed by functional testing.

3. WHITE BOX:
White box testing involves testing the product's underlying structure, architecture, and code to validate input-output flow and enhance design, usability, and security.

4. BLACK BOX:
Black box testing involves testing against a system where the code and paths are invisible.

5. SMOKE TESTING:
This type of software testing validates the stability of a software application, it is performed on the initial software build to ensure that the critical functions of the program are working.

6. RETESTING TESTING:
Testing after debugging to ensure defects are fixed.

7. STATIC TESTING:
In this, we don't execute anything. It includes reviewing the requirement, reviewing the user storage,review the code,revir=ew a prototype of application and give some note about it.

8. DYNAMIC TESTING:
It is used in software engineering to describe the testing of the dynamic behavior of code

### Day 3: 25 febuary 2022 
## TEST PROCESS ACTIVITIES
set of activities that should be followed during software testing to produce quality software or application.

1. Test Planning:
- Determining the scope, objectives, and risks of testing
- Defining the overall approach of testing
- Integrating and coordinating the test activities into the software lifecycle activities
- Making decisions about what to test, the people and other resources required to perform the various test activities, and how test activities will be carried out
- Selecting metrics for test monitoring and control
- Budgeting for the test activities

2. Test Monitoring and Control
- Produce comparison report of actual progress against planned progress
- Test control involves taking actions necessary to meet the objectives of the test plan

3. Test Analysis
- “what to test”
- Analyzing the test basis appropriate to the test level being considered
- Evaluating the test basis and test items to identify defects of various types
- Identifying features and sets of features to be tested

4. Test Design
- “how to test?”
- Designing and prioritizing test cases and sets of test cases
- Identifying necessary test data to support test conditions and test cases
- Designing the test environment and identifying any required infrastructure and tools
- Capturing bi-directional traceability between the test basis, test conditions, and test cases

5. Test Implementation
- “do we now have everything in place to run the tests?”
- Developing and prioritizing test procedures and, potentially creating automated test scripts
- Creating test suites from the test procedures and (if any) automated test scripts
- Arranging the test suites within a test execution schedule in a way that results in efficient test execution
- building the test environment (including, potentially, test harnesses, service virtualization, simulators, and other infrastructure items) and verifying that everything needed has been set up correctly
- Preparing test data and ensuring it is properly loaded in the test environment

6.Test Execution
- Recording the IDs and versions of the test item(s) or test object, test tool(s), and test ware
- Executing tests either manually or by using test execution tools
- Comparing actual results with expected results
- Reporting defects based on the failures observed
- Repeating test activities either as a result of action taken for an anomaly, or as part of the planned testing (e.g., execution of a corrected test, confirmation testing, and/or regression testing)

7. Test Completion
- Checking whether all defect reports are closed, entering change requests or product backlog items for any defects that remain unresolved at the end of test execution
- Creating a test summary report to be communicated to stakeholders
- Finalizing and archiving the test environment, the test data, the test infrastructure, and other test-ware for later reuse
- Handing over the test-ware to the maintenance teams, other project teams, and/or other stakeholders who could benefit from its use
- Analyzing lessons learned from the completed test activities to determine changes needed for future iterations, releases, and projects
- Using the information gathered to improve test process maturity

### Day 4: 25 febuary 2022
## WHAT IS PERFORMANCE TESTING ?
Performance testing is a non-functional software testing technique that determines how the stability, speed, scalability, and responsiveness of an application holds up under a given workload. It’s a key step in ensuring software quality.
The goals of performance testing include evaluating application output, processing speed, data transfer velocity, network bandwidth usage, maximum concurrent users, memory utilization, workload efficiency, and command response times.

Reasons for Performance Testing
- To determine whether the application satisfies performance requirements (for instance, the system should handle up to 1,000 concurrent users).
- To locate computing bottlenecks within an application.
- To establish whether the performance levels claimed by a software vendor are indeed true.
- To compare two or more systems and identify the one that performs best.
- To measure stability under peak traffic events.

### Day 5: 28 febuary 2022
## TYPES OF PERFORMANCE TESTING

1. Endurance Testing
Endurance testing evaluates the performance of the system under load over time. It is executed by applying varying loads to the application under test for an extended period of time to validate that the performance requirements related to production loads and durations of those loads are met.

2. Load Testing
The purpose of load testing is to evaluate the application’s performance under increasingly high numbers of users.

3. Spike Testing
This testing evaluates the ability of the application to handle sudden volume increases. It is done by suddenly increasing the load generated by a very large number of users. The goal is to determine whether performance will suffer, the system will fail, or it will be able to handle dramatic changes in load.

4. Volume Testing
Also known as flood testing, this testing is used to evaluate the application’s ability to handle large volumes of data. The impact on response time and the behavior of the application are analyzed. This testing can be used to identify bottlenecks and to determine the capacity of the system.

5. Stress Testing
This test pushes an application beyond normal load conditions to determine which components fail first. Stress testing attempts to find the breaking point of the application

6. Scalability Testing
This testing is used to determine your application’s ability to handle increasing amounts of load and processing. It involves measuring attributes including response time, throughput, hits and requests per second, transaction processing speed, CPU usage, Network usage and more.

### Day6: 2 March 2022
## INSTALLATION OF SQL
Step 1:

Download installation media from this link:
microsoft.com/en-us/sql-server/sql-server-downloads

Step 2:

Run the downloaded file and you will see the below screen. Now select the third option – Download Media.
![image](https://user-images.githubusercontent.com/52241202/171843703-bd35b9c4-db60-4d0b-b23a-a47e48c66f29.png)

Step 3:

Now you will see the below screen. Please select the language you prefer and select the ISO radio button to download the ISO file. In addition, select the download location of your choice. I will go with the default location. Now press the Download button.
![image](https://user-images.githubusercontent.com/52241202/171843928-c0a36cad-9402-4000-90c9-2df841c7f660.png)

Step 4:

Now it will start downloading SQL Server installation media. It will take some time based on your internet connection speed.

Step 5:

After successful download of installation media. Click the Close button.

### Day7: 3 March 2022
## Basics of SQL

what is database?
A database is an organized collection of data, so that it can be easily accessed and managed.You can organize data into tables, rows, columns, and index it to make it easier to find relevant information.

what is SQL?
SQL or Structured Query Language is used to operate on the data stored in a database.

what is RDBMS?
A relational database management system (RDBMS or just RDB) is a common type of database that stores data in tables, so it can be used in relation to other stored datasets.

What is table?
The data in RDBMS is stored in database objects called tables. The table is a collection of related data entries
and it consists of columns and rows.

What is field?
Every table is broken up into smaller entities called fields.
A field is a column in a table that is designed to maintain specific information about every record in the table.

What is record or row?
A record, also called a row of data, is each individual entry that exists in a table.A record is a horizontal entity in a table.

What is column?
A column is a vertical entity in a table that contains all information associated with a specific field in a table.

What is NULL value?
A NULL value in a table is a value in a field that appears to be blank, which means a field with a NULL value is a
field with no value.

### Day8: 4 March 2022
## Basic Commands in SQL

These SQL commands are mainly categorized into four categories as: 

- DDL – Data Definition Language
- DQl – Data Query Language
- DML – Data Manipulation Language
- DCL – Data Control Language

1.List of DDL commands: 

- CREATE: This command is used to create the database or its objects (like table, index, function, views, store procedure, and triggers).
- DROP: This command is used to delete objects from the database.
- ALTER: This is used to alter the structure of the database.
- TRUNCATE: This is used to remove all records from a table, including all spaces allocated for the records are removed.
- COMMENT: This is used to add comments to the data dictionary.
- RENAME: This is used to rename an object existing in the database.

2.List of DQL: 

- SELECT: It is used to retrieve data from the database.

3.List of DML commands: 

- INSERT : It is used to insert data into a table.
- UPDATE: It is used to update existing data within a table.
-DELETE : It is used to delete records from a database table.

4.List of  DCL commands: 

- GRANT: This command gives users access privileges to the database.
- REVOKE: This command withdraws the user’s access privileges given by using the GRANT command.

### Day9: 7 March 2022
## Data Types in sql

- NUMERIC DATA TYPE:
  - int
  - float
  - decimal
- NON-NUMERIC DATA TYPE:
  - char
  - varchar
  - ENUM
  - Boolean
- DATA AND TIME DATA TYPE:
   - TIME: Time(HHH-MM-SS)
   - YEAR: Year(YYYY)

### Day10: 8 March 2022
## Keys Concept:
Primary key and foreign key

- Primary key:
It is the first key used to identify one and only one instance of an entity uniquely.
- Foreign key:
Foreign keys are the column of the table used to point to the primary key of another table.
- Super Key:
Super key is an attribute set that can uniquely identify a tuple. A super key is a superset of a candidate key.
-  Candidate key:
A candidate key is an attribute or set of attributes that can uniquely identify a tuple.
Except for the primary key, the remaining attributes are considered a candidate key. The candidate keys are as strong as the primary key.
-  Alternate key
There may be one or more attributes or a combination of attributes that uniquely identify each tuple in a relation. These attributes or combinations of the attributes are called the candidate keys. One key is chosen as the primary key from these candidate keys, and the remaining candidate key, if it exists, is termed the alternate key.
- Composite key
Whenever a primary key consists of more than one attribute, it is known as a composite key. This key is also known as Concatenated Key.
- Artificial key
The key created using arbitrarily assigned data are known as artificial keys. These keys are created when a primary key is large and complex and has no relationship with many other relations.

### Day11: 9 March 2022
## SQL clauses:
- CONSTRAINT clause:
A CONSTRAINT clause is an optional part of a CREATE TABLE statement or an ALTER TABLE statement. A constraint is a rule to which data must conform. Constraint names are optional.

- FOR UPDATE clause:
The FOR UPDATE clause is an optional part of a SELECT statement.

- FROM clause:
The FROM clause is a mandatory clause in a selectExpression.

- GROUP BY clause:
A GROUP BY clause, part of a selectExpression, groups a result into subsets that have matching values for one or more columns.

- HAVING clause:
A HAVING clause restricts the results of a GROUP BY in a selectExpression.

- ORDER BY clause:
The ORDER BY clause is an optional element of several statements, expressions, and subqueries.

- USING clause:
The USING clause specifies which columns to test for equality when two tables are joined.

- WHERE clause:
A WHERE clause is an optional part of a selectExpression, DELETE statement, or UPDATE statement. The WHERE clause lets you select rows based on a boolean expression.

### Day12: 10 March 2022
## SQL Functions
SQL has many built-in functions for performing processing on string or numeric data. Following is the list of
all useful SQL built-in functions:
1. SQL COUNT Function - The SQL COUNT aggregate function is used to count the number of rows in a
database table.<br>
SELECT COUNT(*) FROM <Tablename>;

2. SQL MAX Function - The SQL MAX aggregate function allows us to select the highest (maximum) value for a
certain column.<br>
SELECT MAX(*) FROM <Tablename>;

3. SQL MIN Function - The SQL MIN aggregate function allows us to select the lowest (minimum) value for a
certain column.<br>
SELECT MIN(*) FROM <Tablename>;

4. SQL AVG Function - The SQL AVG aggregate function selects the average value for certain table column.<br>
SELECT AVG(*) FROM <Tablename>;

5. SQL SUM Function - The SQL SUM aggregate function allows selecting the total for a numeric column.<br>
SELECT SUM(*) FROM <Tablename>;

6. SQL SQRT Functions - This is used to generate a square root of a given number.<br>
select SQRT(16);

7. SQL RAND Function - This is used to generate a random number using SQL command.<br>
 SELECT RAND( ), RAND( ), RAND( );

8. SQL CONCAT Function - This is used to concatenate any string inside any SQL command.<br>
SELECT CONCAT('FIRST ', 'SECOND');

9. SQL Numeric Functions - Complete list of SQL functions required to manipulate numbers in SQL.

10. SQL String Functions - Complete list of SQL functions required to manipulate strings in SQL.
  
### Day13: 11 March 2022
## TABLES
  
- The CREATE TABLE statement is used to create a new table in a database.<br>
Syntax:<br>
CREATE TABLE table_name (<br>
    column1 datatype,<br>
    column2 datatype,<br>
    column3 datatype,<br>
   ....<br>
);

- Create Table Using Another Table i.e A copy of an existing table can also be created using CREATE TABLE.<br>
Syntax:<br>
CREATE TABLE new_table_name AS <br>
    SELECT column1, column2,... <br>
    FROM existing_table_name <br>
    WHERE ....;
    
- The DROP TABLE statement is used to drop an existing table in a database.<br>
Syntax:<br>
DROP TABLE table_name;

- The ALTER TABLE statement is used to add, delete, or modify columns in an existing table.<br>
Syntax:<br>
ALTER TABLE table_name<br>
ADD column_name datatype;
  
### Day14: 14 March 2022
## SQL Constraints:
Constraints are the rules enforced on data columns on table.<br>
Following are commonly used constraints available in SQL:
1. NOT NULL Constraint: Ensures that a column cannot have NULL value.
2. DEFAULT Constraint: Provides a default value for a column when none is specified.
3. UNIQUE Constraint: Ensures that all values in a column are different.
4. PRIMARY Key: Uniquely identified each rows/records in a database table.
5. FOREIGN Key: Uniquely identified a rows/records in any another table.
  
### Day15: 15 March 2022
## SQL SUBQUERY:
In SQL a Subquery can be simply defined as a query within another query. In other words we can say that a Subquery is a query that is embedded in WHERE clause of another SQL query.<br>

Important rules for Subqueries:

- You can place the Subquery in a number of SQL clauses: WHERE clause, HAVING clause, FROM clause.
- Subqueries can be used with SELECT, UPDATE, INSERT, DELETE statements along with expression operator. It could be equality operator or comparison operator such as =, >, =, <= and Like operator.
- A subquery is a query within another query. The outer query is called as main query and inner query is called as subquery.
- The subquery generally executes first, and its output is used to complete the query condition for the main or outer query.
- Subquery must be enclosed in parentheses.
- Subqueries are on the right side of the comparison operator.
- ORDER BY command cannot be used in a Subquery. GROUPBY command can be used to perform same function as ORDER BY command.
- Use single-row operators with singlerow Subqueries. Use multiple-row operators with multiple-row Subqueries.

Syntax:<br>
SELECT column_name<br>
FROM table_name<br>
WHERE column_name expression operator<br> 
    ( SELECT COLUMN_NAME  from TABLE_NAME   WHERE ... );
  
### Day16: 16 March 2022
## SQL ASSESSMENT
  
### Day17: 17 March 2022
## BASIC JAVA PROGRAMMING

What is Java?<br>
Java is a popular programming language, created in 1995.<br>
It is owned by Oracle, and more than 3 billion devices run Java.<br>

It is used for:

- Mobile applications (specially Android apps)
- Desktop applications
- Web applications
- Web servers and application servers
- Games
- Database connection
- And much, much more!

Why Use Java?<br>
- Java works on different platforms (Windows, Mac, Linux, Raspberry Pi, etc.)
- It is one of the most popular programming language in the world
- It is easy to learn and simple to use
- It is open-source and free
- It is secure, fast and powerful
- It has a huge community support (tens of millions of developers)
- Java is an object oriented language which gives a clear structure to programs and allows code to be reused, lowering development costs
- As Java is close to C++ and C#, it makes it easy for programmers to switch to Java or vice versa

Java Syntax:
- Main.java

public class Main {<br>
  public static void main(String[] args) {<br>
    System.out.println("Hello World");<br>
  }<br>
}

- The main Method

public static void main(String[] args)

- System.out.println()

public static void main(String[] args) {<br>
  System.out.println("Hello World");
}

Java Variables:<br>
A variable is a container which holds the value while the Java program is executed.<br>
A variable is the name of a reserved area allocated in memory. In other words, it is a name of the memory location. It is a combination of "vary + able" which means its value can be changed.<br>

Types of Variables:<br>
There are three types of variables in Java:
  
- Local Variable
A variable declared inside the body of the method is called local variable. You can use this variable only within that method and the other methods in the class aren't even aware that the variable exists.<br>

A local variable cannot be defined with "static" keyword.<br>

- Instance Variable
A variable declared inside the class but outside the body of the method, is called an instance variable. It is not declared as static.<br>

- Static variable
A variable that is declared as static is called a static variable. It cannot be local. You can create a single copy of the static variable and share it among all the instances of the class. Memory allocation for static variables happens only once when the class is loaded in the memory.<br>
  
DATA TYPES:<br>
Java defines eight simple (or elemental) types of data: byte, short, int, long, char, float,double,
and boolean. <br>
These can be put in four groups:
- Integers: This group includes byte, short, int, and long, which are for whole valued signed numbers.
- Floating point numbers: This group includes float and double, which represent numbers with fractional precision.
- Characters: This group includes char, which represents symbols in a character set, like letters and numbers.
- Boolean: This group includes boolean, which is a special type for representing true/false values.
  
### Day18: 21 March 2022
## CONDITIONAL,LOOPS And OOPS CONCEPTS
 
Conditional Statements:<br>

- if:<br>
if(condition) <br>
{<br>
   // Statements to execute if<br>
   // condition is true<br>
}<br>

- if-else:<br>
if (condition)<br>
{<br>
    // Executes this block if<br>
    // condition is true<br>
}<br>
else<br>
{<br>
    // Executes this block if<br>
    // condition is false<br>
}<br>

- Nested if-else-if:<br>
if (condition)<br>
    statement;<br>
else if (condition)<br>
    statement;<br>
.<br>
.<br>
else<br>
    statement;<br>

- Switch:<br>
switch (expression)<br>
{<br>
  case value1:<br>
    statement1;<br>
    break;<br>
  case value2:<br>
    statement2;<br>
    break;<br>
  .<br>
  .<br>
  case valueN:<br>
    statementN;<br>
    break;<br>
  default:<br>
    statementDefault;<br>
}<br>

- Break:<br>
In Java, a break is majorly used for:<br> 
Terminate a sequence in a switch statement (discussed above).<br>
To exit a loop.<br>
Used as a “civilized” form of goto.<br>

- Continue:<br>
Sometimes it is useful to force an early iteration of a loop. That is, you might want to continue running the loop but stop processing the remainder of the code in its body for this particular iteration.<br>

- Return:<br> 
The return statement is used to explicitly return from a method. That is, it causes program control to transfer back to the caller of the method.<br>

LOOPS:<br>
- For loop:  
for(initializing statement;testing condition;increment/decrement) <br>
{ <br>
//code to be iterated <br>
} <br>

- While:  
while(boolean condition) <br>
{ <br>
//statements; <br>
} <br>

- Do-While:  
do{   <br>
//code to be executed / loop body   <br>
//update statement    <br>
}while (condition); <br>
  
OOPS CONCEPT:<br>
The primary purpose of object-oriented programming is to increase the flexibility and maintainability of programs.<br>
- Class:<br>
A class is a template for multiple objects with similar features. Classes embody all the features of a particular set of objects.<br>
class MyClassName {<br>
...<br>

- Object:<br>
An object in java is an identifiable entity that has some characteristics and behavior. We create objects from class in Java.<br>
< className > <objectName > =new < className> ();<br>
Object in Java can be created in any of the following ways using:<br>
  - new operator<br>
  - new instance<br>
  - clone() method<br>
  - deserialization<br>

- Polymorphism: <br>
It is an important concept of object-oriented programming. It simply means more than one form.
That is, the same entity (method or operator or object) can perform different operations in different scenarios.
  
- Inheritance: <br>
It is one of the key features of OOP that allows us to create a new class from an existing class.
It is one of the key features of OOP that allows us to create a new class from an existing class.
The new class that is created is known as subclass (child or derived class) and the existing class from where the child class is derived is known as superclass (parent or base class).
  
- Abstraction: <br>
Hiding internal details and showing functionality is known as abstraction. For example phone call, we don't know the internal processing.
  
- Encapsulation: <br>
Binding (or wrapping) code and data together into a single unit are known as encapsulation. For example, a capsule, it is wrapped with different medicines.
  
### Day19: 22 March 2022
## IMPORTANT CONCEPTS
- ARRAY: <br>
An array in Java is a linear and homogeneous collection of the same type of elements. In array, there is contiguous memory allocation. An array is basically a group of similar variables referred under a common name. An array is a user-defined data type. <br>  
Syntax of array: <br>
int intArray[];  //declaring array <br>
intArray = new int[20];  // allocating memory to array <br>  
There are two types of arrays in Java:
   - One-dimensional arrays
   - Multi-dimensional arrays <br>
  
- STRING:<br>
There are many ways to create a string object in java, some of the popular ones are given below.<br> 
   - Using string literal <br> 
    String str = "abc"; 

   - Using new keyword <br> 
    String str  =  new String("abc"); <br> 
    char[] a = {'a', 'b', 'c'}; <br> 
    String str2  =  new String(a); <br>
  
- CONSTRUCTOR: <br>
A Constructor in Java is a block of code that creates an object. Therefore, it is also called an object builder in Java. The constructor is very similar to a Java method. The main difference between them is that a constructor does not have a return type, not even void, unlike methods. <br>  
There are two types of constructors in Java:
  - Default constructor
  - Parameterized constructor

- METHOD OVERRIDING: <br>
In method overriding, the child class can use the OOP polymorphism concept to override a method of its parent class. That allows a programmer to use one method in different ways depending on whether it’s invoked by an object of the parent class or an object of the child class.
- METHOD OVERLOADING: <br>
In method overloading, a single method may perform different functions depending on the context in which it’s called. This means a single method name might work in different ways depending on what arguments are passed to it.

- INTERFACE: <br>
A collection of abstract behavior specifications that individual classes can then implement.<br>
Syntax: <br>
interface < interfaceName > { <br>
  //static functions <br>
  //abstract methods <br>
} <br>
- PACKAGE: <br>
 A collection of classes and interfaces. Classes from packages other than java.lang must be explicitly imported or referred to by full package name.
  
### Day20: 23 March 2022
## Keywords
- Static keyword: <br>
   - The static keyword in java is used for memory management mainly.
   - Static member of class belongs to class itself instead of the class object.
   - Constructor cannot be static.
   - A static variable gets memory only once in the class area at the time of class loading.
- This keyword: <br>
This keyword in Java is a reference variable that refers to the current object of a method or a constructor. The main purpose of using this keyword in Java is to remove the confusion between class attributes and parameters that have same names. <br>
Following are various uses of ‘this’ keyword in Java: <br>
   - It can be used to refer instance variable of current class
   - It can be used to invoke or initiate current class constructor
   - It can be passed as an argument in the method call
   - It can be passed as argument in the constructor call
   - It can be used to return the current class instance.
- Final keyword: <br>
The final keyword in java is used to restrict the user.
    - Java final variable
      If you make any variable as final, you cannot change the value of final variable(It will be constant).
    - Java final method
      If you make any method as final, you cannot override it.
    - Java final class
 If you make any class as final, you cannot extend it.

- Super keyword: <br>
The super keyword in Java is used in subclasses to access superclass members (attributes, constructors and methods). <br>
Uses of super keyword-
   - To call methods of the superclass that is overridden in the subclass.
   - To access attributes (fields) of the superclass if both superclass and subclass have attributes with the same name.
   - To explicitly call superclass no-arg (default) or parameterized constructor from the subclass constructor.
  
### Day 21: 24 March 2022
## EXCEPTIONAL HANDLING
Java Exceptions: <br>
An exception is an unexpected event that occurs during program execution. It affects the flow of the program instructions which can cause the program to terminate abnormally. <br>
An exception can occur for many reasons. Some of them are:
- Invalid user input
- Device failure
- Loss of network connection
- Physical limitations (out of disk memory)
- Code errors
- Opening an unavailable file<br>
  
Java Exception Types:
1. RuntimeException <br>
A runtime exception happens due to a programming error. They are also known as unchecked exceptions. <br>
These exceptions are not checked at compile-time but run-time.<br>
Some of the common runtime exceptions are:
- Improper use of an API - IllegalArgumentException
- Null pointer access (missing the initialization of a variable) - NullPointerException
- Out-of-bounds array access - ArrayIndexOutOfBoundsException
- Dividing a number by 0 - ArithmeticException
2. IOException <br>
An IOException is also known as a checked exception. They are checked by the compiler at the compile-time and the programmer is prompted to handle these exceptions. <br>
Some of the examples of checked exceptions are:
- Trying to open a file that doesn’t exist results in FileNotFoundException
- Trying to read past the end of a file
  
**Java try...catch block:** <br>
The try-catch block is used to handle exceptions in Java.<br>
 
Here's the syntax of try...catch block: <br>
try { <br>
  // code <br>
} <br>
catch(Exception e) { <br>
  // code <br>
} <br>

**Java finally block:** <br>
In Java, the finally block is always executed no matter whether there is an exception or not. The finally block is optional. And, for each try block, there can be only one finally block.<br>
 
The basic syntax of finally block is: <br>
try { <br>
  //code <br>
} <br>
catch (ExceptionType1 e1) {  <br>
  // catch block <br>
} <br>
finally { <br>
  // finally block always executes <br>
} <br>

**Java throw and throws keyword:** <br>
The Java throw keyword is used to explicitly throw a single exception.When we throw an exception, the flow of the program moves from the try block to the catch block. <br>
 
Example: Exception handling using Java throw <br>
class Main { <br>
  public static void divideByZero() { <br>

    // throw an exception <br>
    throw new ArithmeticException("Trying to divide by 0"); <br>
  } <br>

  public static void main(String[] args) { <br>
    divideByZero(); <br>
  } <br>
} <br>
 
Syntax of **Nested try Catch...**<br>
//Main try block <br>
try { <br>
   statement 1; <br>
   statement 2; <br>
   //try-catch block inside another try block <br>
   try { <br>
      statement 3; <br>
      statement 4; <br>
      //try-catch block inside nested try block <br>
      try { <br>
         statement 5; <br>
         statement 6; <br>
      } <br>
      catch(Exception e2) { <br>
         //Exception Message <br>
      } <br>
   } <br>
   catch(Exception e1) { <br>
       //Exception Message <br>
   } <br>
   
} <br>
//Catch of Main(parent) try block <br>
catch(Exception e3) { <br>
      //Exception Message  <br>
}  <br>
....  <br>
  
### Day22: 25 March 2022
## JAVA ASSESSMENT
  
### Day 23: 28 March 2022
## PERFORMANCE TESTING CONCEPTS
What is Performance testing? <br>
Performance Testing is a software testing process used for testing the speed, response time, stability, reliability, scalability and resource usage of a software application under particular workload. The main purpose of performance testing is to identify and eliminate the performance bottlenecks in the software application. It is a subset of performance engineering and also known as “Perf Testing”. <br>  

Why do Performance Testing? <br>
Features and Functionality supported by a software system is not the only concern. A software application’s performance like its response time, reliability, resource usage and scalability do matter. The goal of Performance Testing is not to find bugs but to eliminate performance bottlenecks. <br>
Performance Testing is done to provide stakeholders with information about their application regarding speed, stability, and scalability. More importantly, Performance Testing uncovers what needs to be improved before the product goes to market. Without Performance Testing, software is likely to suffer from issues such as: running slow while several users use it simultaneously, inconsistencies across different operating systems and poor usability. <br>
Performance testing will determine whether their software meets speed, scalability and stability requirements under expected workloads. Applications sent to market with poor performance metrics due to nonexistent or poor performance testing are likely to gain a bad reputation and fail to meet expected sales goals. <br> 

Types of Performance Testing <br>
1. Load testing – checks the application’s ability to perform under anticipated user loads. The objective is to identify performance bottlenecks before the software application goes live.
2. Stress testing – involves testing an application under extreme workloads to see how it handles high traffic or data processing. The objective is to identify the breaking point of an application.
3. Endurance testing – is done to make sure the software can handle the expected load over a long period of time.
4. Spike testing – tests the software’s reaction to sudden large spikes in the load generated by users.
5. Volume testing – Under Volume Testing large no. of. Data is populated in a database and the overall software system’s behavior is monitored. The objective is to check software application’s performance under varying database volumes.
6. Scalability testing – The objective of scalability testing is to determine the software application’s effectiveness in “scaling up” to support an increase in user load. It helps plan capacity addition to your software system. <br>  

Common Performance Problems <br>
Most performance problems revolve around speed, response time, load time and poor scalability. Speed is often one of the most important attributes of an application. A slow running application will lose potential users. Performance testing is done to make sure an app runs fast enough to keep a user’s attention and interest. Take a look at the following list of common performance problems and notice how speed is a common factor in many of them: 
- Long Load time – Load time is normally the initial time it takes an application to start. This should generally be kept to a minimum. While some applications are impossible to make load in under a minute, Load time should be kept under a few seconds if possible.
- Poor response time – Response time is the time it takes from when a user inputs data into the application until the application outputs a response to that input. Generally, this should be very quick. Again if a user has to wait too long, they lose interest.
- Poor scalability – A software product suffers from poor scalability when it cannot handle the expected number of users or when it does not accommodate a wide enough range of users. Load Testing should be done to be certain the application can handle the anticipated number of users.
- Bottlenecking – Bottlenecks are obstructions in a system which degrade overall system performance. Bottlenecking is when either coding errors or hardware issues cause a decrease of throughput under certain loads. Bottlenecking is often caused by one faulty section of code. The key to fixing a bottlenecking issue is to find the section of code that is causing the slowdown and try to fix it there. Bottlenecking is generally fixed by either fixing poor running processes or adding additional Hardware. Some common performance bottlenecks are
   - CPU utilization
   - Memory utilization
   - Network utilization
   - Operating System limitations
   - Disk usage <br> 

Performance testing tools (Load testing tools):  <br>
When we have to measure the load, stability, response time of the application, we required some performance (load) testing tools, which help us to test the performance of the software or an application. Performance testing tools can be open-source and commercial.<br>

We have various types of performance testing tools available in the market; some of the most used performance (load) testing tools are as follows: <br>

- Apache JMeter
- LoadRunner[HP]
- LoadNinja
- WebLOAD
- LoadComplete
- NeoLoad
- LoadView

Importance Of Performance Testing: <br>
There are several reasons that you should consider performance testing your application. Some of those reasons are technical, but perhaps the most important is ensuring your web application, website, and server are all acting as expected under increased load. <br>
Regular performance tests will help ensure your website performs at its highest level, resulting in better uptime, less maintenance, and greater user interactivity while on site. <br> 

INTRODUCTION TO LOAD RUNNER(LR)  <br> 

What is Load runner? <br>
LoadRunner is a Performance Testing tool which was pioneered by Mercury in 1999. LoadRunner was later acquired by HPE in 2006. In 2016, LoadRunner was acquired by MicroFocus. <br>
LoadRunner supports various development tools, technologies and communication protocols. In fact, this is the only tool in market which supports such a large number of protocols to conduct Performance Testing. Performance Test Results produced by LoadRunner software are used as a benchmark against other tools. <br> 

Why LoadRunner? <br>
LoadRunner is not only pioneer tool in Performance Testing, but it is still a market leader in the Performance Testing paradigm. In a recent assessment, LoadRunner has about 85% market share in Performance Testing industry. <br> 

What is LoadRunner Architecture? <br>
Broadly speaking, the architecture of HP LoadRunner is complex, yet easy to understand. <br> 

There are three components of LR: <br>
1. VuGen 
2. Controller
3. Analysis <br> 

VuGen (Virtual User Generator): <br>
‘VuGen’ (Virtual User Generator) which is the first component of the LoadRunner tool. It is used to capture the network traffic (or requests) and create scripts that emulate the real user actions on a web Application (or a Desktop application).
VuGen captures the HTTP traffic when we perform actions on an application and converts the same into a script (which when replayed emulates the real user actions on the application). <br>
The script is nothing but the HTTP request(s) which is put in the form of functions <br> 


Controller: <br>
Controller, as the name suggests, is a program to “control” overall load test. It is responsible for helping you run your performance test design using the VUGen scripts you’ve already created. It lets you over-ride run-time settings, enable or disable think time, rendezvous points, adds load generators and controls the number of users each generator can simulate. It automatically creates a dump of execution results, gives you a live view of “current state” of load test running. <br> 

There are two types of scenarios in Controller:- <br>

- Manual Scenario
- Goal-Oriented Scenario

1. Manual Scenario
A manual scenario is static and gives more control over the situation. You can decide which transaction to execute, for how many of times, for how long. <br>
Based on the composition of test mix, you can see application behaviour such as number of hits, response time, etc. <br> 

2. Goal-Oriented Scenario
A Goal-Oriented scenario is dynamic in nature – this means, it keeps changing the overall load being simulated over the server. You set a Goal, for example, the maximum number of hits you wish to achieve for the target server, maximum response time against a transaction etc.  <br>  

Analysis: <br>
Analysis, the LoadRunner Professional tool for gathering and presenting load test data. When you execute a load test scenario, Vusers generate result data as they perform their transactions. <br>
Analysis provides graphs and reports enabling you to view and understand the data, and analyze system performance after a test run. <br> 

Analysis provides the following tools to view results: <br>

- Graphs:- Standard and protocol-specific graphs help you determine system performance and provide information about transactions and Vusers. You can compare multiple graphs by combining results from several load test scenarios or merging several graphs into one. <br>
Each graph has a legend which describes the metrics in the graph. You can also filter your data and sort it by a specific field.

- Analysis graph data and raw data views:- These views display the actual data used to generate the graph in a spreadsheet format. You can copy this data into external spreadsheet applications for further processing.

- Analysis reports:- This utility enables you to generate a summary of each graph. The report summarizes and displays the test's significant data in graphical and tabular format. You can generate reports based on customizable report templates.

### Day 24: 29 March 2022
## Scripting Overview, Actions, Transactions, RTS & Verification checks
What is scripting? <br>
It is the process by which user actions are captured by loadrunner at the protocol level. <br>
Scripting is essential to simulate different actions of users and their behaviour in the load test. <br>

Actions:<br>
An action is set of user transactions performed in the System Under Load to achieve a defined task. An action can be compared to a function in other programming languages. Each Vuser script has 3 default functions <br>

- Vuser_init(used to login into the application)
- Action (used to record the business process)
- Vuser_end (used to logout of the application)

Transactions: <br>
A transaction defines a set of end-user actions that represent the real user activities on an application. A transaction can have multiple requests or sequence of actions which hit the server at a predefined rate (SLA).  <br>
A LoadRunner script can have an unlimited number of transactions/sub-transactions with a different name. Ideally, each user action should be captured in an individual transaction. Example: login, search, submit an order, logout, etc. Each transaction has its own section fenced by start and end transaction function. <br> 

Runtime Settings <br>
1. General->Run Logic:
2. General->Pacing:
3. General->Log:
4. General->Think Time:
5. General->Additional Attributes:
6. General->Miscellaneous:
7. Browser->Browser Emulation:
8. Network->Speed Simulation:
9. Network->Streaming:
10. Internet Protocol->Content Check:
11. Internet Protocol->Proxy:
12. Internet Protocol->Preferences:
13. Internet Protocol->Download Filters:
14. Data Format Extension->Chain Configuration

Verification Checks: <br>
Text and Image checks – To ensure that the response returned is correct. <br> 

- Text checks: <br>
Text checks are used to verify if the response returned for the request is correct or not.sometimes VuGen may not show any error but the returned response may not be the correct one. So, to ensure that the response is correct, we use text checks.
For text check, we use ‘web_reg_find’ function just before the request. <br> 
The syntax of this function is: <br>

web_reg_find(“Text=”,”SaveCount=”,”Fail=”,LAST); 

- Image check: <br>
Image check is used to verify the presence of a specified image in a response. ‘web_image_check’ function is used for image check. This function has to be put after the request (in the response of which we are expecting the image). <br>  
Example of this function: <br>

web_image_check(“Image”,”Src=/WebTours/images/flights.gif”,LAST) <br>

### Day 25: 30 March 2022
## DOUBT CLARIFICATION SESSION WITH INSTRUCTOR
 
### Day 26: 31 March 2022
## LR PARAMETERIZATION
What is Parameterisation? <br>
Parameterization is a method to replace the hardcoded value like application URL, User Name, Password etc. with a parameter which has different input values. <br>
Example: You recorded a login page of an application by providing the credentials USER1 and PASS1. When you replay the script, the same credentials are passed. Now, if you want to run a test with 5 different users (USER2, USER3, USER4, USER5 and USER6) then you need to replace the hardcoded value i.e. USER1 with a parameter (say p_userID). This parameter will have a list of all the given values and pass them at the time of the test execution. <br>

Hence a parameter is used to pass different input values in the script. <br>  

How to do parameterization in LoadRunner?  <br>
There are 2 methods to do parameterization in LoadRunner:  <br>

a) When you do not have a predefined parameter list:
  - Go to the script.
  - Select the value (text) which you want to parameterize.
  - Right-click on the selected text.
  - Click ‘Replace with Parameter’ option.
  - Click ‘Create New Parameter…’
  - ‘Select or Create Parameter’ pop-up will open then provide the value for ‘Parameter name’ and ‘Parameter type’ field and click ‘Ok’ button.
  - Another pop-up will appear stating ‘Do you want to replace all occurrences of the string with parameter?’. Click ‘Yes’ to replace all the occurrences of the text. This will replace the parameterized value with the parameter name.
  - Set the scope of the replacement and click on the suitable option. ‘Find Next’ option identifies the next occurrence of the text. ‘Replace’ option replaces the highlighted text only whereas ‘Replace All’ option replaces all the occurrences of the text as per the selected scope. <br>

b) When you have a predefined parameter list:
  - Go to the script.
  - Select the value (text) which you want to parameterize.
  - Right-click on the selected text.
  - Click ‘Replace with Parameter’ option.
  - Choose an appropriate parameter suggested below the ‘Parameter List…’.
  - A pop-up appears stating ‘Do you want to replace all occurrences of the string with parameter?’. Click ‘Yes’ to replace all the occurrences of the text. This will replace the parameterized value with the parameter name.
  - Set the scope of the replacement and click on the suitable option. ‘Find Next’ option identifies the next occurrence of the text. ‘Replace’ option replaces the highlighted text only whereas ‘Replace All’ option replaces all the occurrences of the text as per the selected scope. <br>  

How to restore the original value of the parameter in LoadRunner? <br>
- Right-click on the parameter which you want to be restored.
- Click ‘Restore original value’.
 
### Day 27: 1 April 2022
## DOUBT CLARIFICATION SESSION WITH INSTRUCTOR

### Day 28: 4 April 2022
## CORRELATION
What is Correlation? <br>
‘Correlation’ term refers to the handling of dynamic values coming from the server. These dynamic values are the unique values which are generated by the server for security purpose like the session ID, authorization token etc. In some cases, dynamic values also refer to the web content like values in a drop-down list, calendar date, item ID, product ID, order number etc. Through correlation, you can capture these dynamic values and pass in the subsequent requests. This is the basic concept of ‘Correlation’ in LoadRunner. <br>  
Why do we need to correlate the dynamic values? <br>
To get the answer to this question, firstly you need to understand what exactly happens at the time of script recording, script replay and after correlating the dynamic values. <br> 

Let’s see, how the client and server act when some dynamic values are exchanged between them? <br>
When you replay the script without any changes then the script fails because of the dynamic value (sessionid) generated by the server does not match with the value return back by the client. <br>
while replaying the script, the server generated the session id as 222, but vuser script sent the recorded value i.e. 111 which was captured during recording (Figure 01). Hence the server refused to serve the request and threw an error. <br>
Now, when you correlate the dynamic value (sessionid) and replay the script then the vuser script captures and saves the latest value generated by the server and sends back to the server in the next request. The server validates the returned value with generated value and gives the proper response. Hence the request is marked as passed at user end. <br> 

What are the common values which require correlation? <br>
- Session ID
- Access Token
- Customer Name / ID
- Order Number
- Bill Number
- Number of records displayed on a page
- Current Date and Time <br>  

There could be more values which depend on the type of the application and the term used to denote them. <br>  

In LoadRunner, there are two methods to correlate the dynamic values which are: <br>

- Automatic Correlation
- Manual Correlation

If we further categories automatic and manual correlation then we can see there are multiple methods to find out the dynamic values in the script. Those methods are: <br>

1. Automatic Correlation
  - before recording (Rules)
  - after recording (Record)
  - after replay (Replay)
2. Manual Correlation
  - Using WDiff (By comparing two scripts for identical flow)
  - Using Replay Log

### Day 29: 5 April 2022
## DOUBT CLARIFICATION SESSION WITH INSTRUCTOR

### Day 30: 6 April 2022
## SCRIPTING STANDARDS AND LR FUNSTIONS
Scripting Standards: <br>
Whenever a team of performance testers grows larger than three people, then it is time to assemble the team and create some LoadRunner scripting standards. <br>
scripting standards helps junior performance testers avoid common mistakes and follow best practices. Experienced performance testers benefit from having consistency between scripts, so there is less confusion when work is transferred between team members. <br>
It is common for VuGen scripting standards to require that each script has a standard header with the performance testers name and email address, a description of the business process steps, and any useful notes or caveats. <br>
VuGen Script Templates are an easy way to ensure that all scripts start with a comment block containing placeholders to remind the performance tester to include this information. <br>  

Transaction Naming Convention: <br>
The transaction naming conventions I use when load testing in any tool.The most important thing is to start the transaction name with the script number, followed by the step number for the script. This allows the transactions to be sorted in a final report. <br>
Naming controls is a hold-over from functional testing. Load testing is NOT functional test.  <br>

i)Transaction Naming Convention, General Approach: <br>

The following format should be used for transaction names within a script: <br> 

<Script#><Step#><ModuleName><SubmodName><ShortDescriptionOfAction> <br> 

E.g., <br>

021_002_FIN_PC_BudgetPlanLink <br>  

Note the following: <br>

Transaction names should usually begin with the script number (except in the very rare case where multiple online applications are executed in the same test) <br>
The general approach to naming is hierarchical. The script number, step number, module, submodule, then a description of the step. <br>
We especially want the script number to precede the everything else, generally followed by the script step number. This ensures that in reports we can group by script number and trace down each step through the customer scenario. Grouping per scenario, and ordering by step, helps determine where that scenario might have a performance problem, and helps produce a report which clarifies to the customer where his business scenario is likely to break. <br>
Use an underscore between elements and Camel Case notation (no underscores, no spaces) for the step description.
Script numbers and step numbers have two leading zeros for a total of three digits. <br>
The step description should describe the business action, not the HTML control or action. (For more about this see the discussion under “Background”, below). <br>
The use of “_Click” and similar suffixes describing the action on a control is now deprecated for LoadRunner scripting. This is a change from previous naming recommendations and may be different than the convention for functional tools like QTP. 55% of LoadRunner actions are a left-clicks, and usually only three controls are used: buttons, links, and drop downs (occasionally a tab). Therefore repeatedly describing these actions is repetitive, does not distinguish the action very well, and unnecessarily lengthens the transaction name. Naming the control and the action is a hold-over from functional UI testing that does not really apply to LoadRunner. For more about this see the discussion under “Background”, below. <br>
If we are going to use a LaunchApp transaction, it should start numbering with transaction 000 (not 001). <br>
If multiple applications need to be executed together in the same test, then the application name and/or the script type (online, batch, or integration) should prefix the number. <br>
<AppName><ScriptType><Script#><Step#><ModuleName>_<SubmodName>_ShortDescriptionOfAction>. <br> 

ii)Mandatory End-To-End Transaction <br>

All scripts should include an extra (not provided by the customer) transaction which measures the execution time for the entire scenario. Let’s call this an “End-to-End” (ETE) transaction because it measures the end-to-end time for the entire scenario. The start of this transaction should be in first action block right after user log in, and the end transaction should be in the last action block just before user log out. ETE transactions have three purposes: <br>

  - ETE transactions tell us at a glance how many of the customer scenarios are actually making it to completion. For each scenario that fails to make it to completion, we should be able to find a corresponding error in the LoadRunner controller.
  - ETE transactions are the “canaries in the coal mine.” Failure to reach them in the expected quantities is an early indication that we are not executing a good test.
  - At the end of a test, ETE transactions provide proof that we have executed the work load specified by the customer.
  - The response time of the ETE transaction is extremely useful for setting the pacing for the script when using a transaction-based pacing approach (more details on that elsewhere.) <br>  
Format for ETE transactions : <br>

ETE_<Script#><ModuleName><SubmodName>_<ScriptName> <br> 
e.g., <br>
ETE_021_FIN_PC_BudgetDetailLink <br>  

iii) Inclusive (or Nested or “Outer”) Transactions <br>

In general, try not to use too many nested (inclusive or “outer”) transactions within a script. <br>
If there is a temptation to use many of nested transactions, it is likely that the customer’s scenario is too long. (Under load, long scenarios are likely to have a perf problem in the middle of the scenario, preventing the rest of the scenario from executing). <br>
Inclusive transactions that are not labeled as inclusive are easily confused with long response times of normal requests. At the end of the test, our goal is to gather and report on all response times and sort them by duration. In general, inclusive response times just confuse this report; inclusive transactions look like long response times, but they are actually multiple requests in one transaction. Best practice is to justify their use and be highly selective about them. <br>
If inclusive transactions are needed, the word “Inclusive” should be used in the transaction name after the step number name. <br>  
<Script#><Step#>_Inclusive<ModuleName><SubmodName>_ShortDescriptionOfAction>. <br>
E.g.,  <br>
021_003 Inclusive_FIN_PC_ProjectCosting_Budgeting_BudgetDetail <br>  

iv)Other conventions <br>

Do not use hyphens or spaces in transaction names. Use underscores instead. Hyphens prevent our ability to highlight the transaction name with one mouse click and paste it to the End transaction. <br>
Avoid decimal points in transaction names, for same reason as hypens. If a new transaction needs to be inserted in the scenario, and you don’t want to renumber the entire scenario, use “a”, “b” , “c” instead. E.g., 3a_, 3b_, 3c_. <br>
Avoid using underscores between the words in the action description (use underscore only as an element separator). Use Camel Case, with no spaces, for the description of the action. <br>
Try to keep the transaction names short. Long transaction names can make some LoadRunner reports wrap the transaction name to the next line. This makes it difficult to paste the results into Excel and sort by response times or errors. Particularly if you need to include that transaction name on a graph (e.g., response time as a function of users or throughput), long names are a significant handicap. <br>  
Use abbreviations in the descriptions by omitting the vowels from the word. E.g., <br>
  -  BU_ = Business Unit
  -  LkUp = Look up
  -  Ctrl = control
  -  Proj = Project
  -  Acct = Account
  -  PO = Purchase Order
  - PR = Purchase requisition
  - LI = Line Item
  - ProcMon = Process Monitor
  - Save = ClickOnSaveButton <br> 

Mouse clicks which contain no code in the LoadRunner recording– because these are client side JavaScript actions and do not make calls to the server – should not be given a transaction number or name
Background Information <br>
Avoiding the word “click” in the Transaction Name <br>  

In contrast, the following things are true about testing with LoadRuner HTML protocol (as well as for other high-volume load tools): <br> 

a) There are less controls on an HTML web page than on a desktop application. <br>
b) There are less actions possible to HTML controls. Usually the only action is a left mouse click; this click is limited to about three controls: Links, buttons, and option select controls. <br>
c) Further limiting the number of controls and actions available in load testing is the fact LoadRunner can ONLY test actions which generate a request to the server. (GETs, POSTS, PUTS and other REST-oriented requests. LoadRunner only tests actions which go through the network card. By its normal default use, LoadRunner does not record any UI behaviors generated by JavaScript (unless the JavaScript generates an XMLHTTP request). The matrix of UI actions LoadRunner is capable of testing is therefore very limited. If this small matrix is used in every transaction name, the names up being repetitive and this is counter to the purpose of identifying the actions. It is more distinguishing to and more unique identifies what is happening to describe the action in terms of a business process.) <br>
d) During replay, LoadRunner does not instantiate an instance of the application at all. Unlike UI testing tools, LoadRunner doesn’t look for HTML controls during replay at all; it merely sends the GET or POST request. (We are always testing the server when we use LoadRunner, not the UI. It would makes more sense to describe actions on the server than in terms of UI controls.) <br>
e) LoadRunner HTML does not work by searching an “Object Repository” in order to find a control (except for TruClient, LoadRunner works by parsing the incoming stream of HTML.) <br>
These characteristics of load testing can be summed up by saying that when we use LoadRunner, we are not functionally testing a UI, we are testing code on the server, which is actually UI-less. We are specifically testing the ability of the server to respond to particular scenarios defined by the business. It makes much more sense, therefore, to name the transactions in terms of either business actions or server actions than it does to clutter the valuable transaction name real estate with control names. <br>  
 
LoadRunner (LR) Functions: <br>

These functions are the general LoadRunner functions that are common for all protocols: <br>

1. lr_eval_string(): As already seen, this function returns the input string after evaluating any embedded parameters.

2. lr_eval_string_ext(): This function creates a buffer and assigns it to the input string after evaluating the embedded parameters.

3. lr_save_string(): As already seen, this function assigns a value to the LR parameter/variable.

4. lr_save_int(): This function assigns an integer to an LR parameter as shown below: <br> 
Example: <br> 
int number; <br>
number=8; <br>
lr_save_int(number,”numparam”); <br>
The parameter ‘numparam’ can now be used as any other LR parameter. <br>

5. lr_paramarr_random(): As already seen, this function randomly selects one of the values from a parameter array.

6. lr_paramarr_len(): This function returns the number of elements in a parameter array.

7. lr_message(): This is a message function that is used to send a message(s) to the log and the output window.

8. lr_output_message(): This is a message function that is used to send the message(s) with details like the script section and line number to output windows, log files and other test report summaries.

9. lr_abort(): This function aborts the execution of the script after executing the ‘vuser_end’ section. This function is useful when we need to manually abort the script because of a specific error condition.

10. lr_exit(): This function instructs Vuser to exit from the script run during execution and continue as per the ‘Script Continuation Options’ specified.

11. lr_think_time(): This function allows a Vuser to pause for a defined time between steps/actions on the VuGen script. This is to simulate the real user behavior of thinking for some time between actions/steps on an application. <br>

web_reg_save_param(): As already seen, this is a boundary based correlation function. <br>

12. web_reg_save_param_ex(): This is also a boundary based correlation function which is a improved version of the web_reg_save_param function.

13. web_reg_find(): As already seen, this function is used for text check.

14. web_image_check(): As already seen, this function is used for image check.

15. web_convert_param(): This function is used to convert HTML text to plain text or URL, or plain text to URL. In the below Example, these functions convert the content of parameter ‘ParamName’ from the HTML format to URL format.

### Day 31: 7 April 2022
## DOUBT CLARIFICATION SESSIONS WITH INSTRUCTOR

### Day 32: 8 April 2022
## BASICS OF CONTROLLER
What is Controller? <br>
Controller, as the name suggests, is a program to “control” overall load test. It is responsible for helping you run your performance test design using the VUGen scripts you’ve already created. It lets you over-ride run-time settings, enable or disable think time, rendezvous points, adds load generators and controls the number of users each generator can simulate. It automatically creates a dump of execution results, gives you a live view of “current state” of load test running. <br>  

How to Launch Controller <br>
To launch Controller, go to Start Menu ->Software ->LoadRunner ->Controller <br> 

The snapshot will automatically lead to the main window of HP Controller. Let’s have a look at it before we discuss main components of the screen. <br> 

If the “New Scenario” screen doesn’t come up automatically, (after you’ve changed the preference) you can click on New button under File Menu or click on How to use Controller in LoadRunner button from the toolbar. Alternatively, you can click Ctrl + N. The menu has been displayed below for reference. <br> 

Similarly, to open an existing or previously created scenario you can use Ctrl + O or How to use Controller in LoadRunner icon, and it will open a standard dialogue box to browse files. The extension of a Load Runner Scenario file is *.lrs  <br>  

There are two types of scenarios in Controller. <br>

- Manual Scenario
- Goal-Oriented Scenario

‘Scenario Preparation’ is one of the important steps in LoadRunner and it comes after the completion of test scripts. When the test scripts work properly on the local machine then you can upload them in Controller (Loadrunner Professional) or LoadRunner Enterprise and start creating the scenario as per the requirement. <br>
Scenario designing or preparation is related to workload modelling. In which you should know the value of all the key inputs like user load, test duration, ramp-up, ramp-down, steady-state period, expected TPS, pacing etc. Without these inputs, you can not design an accurate scenario or workload model. <br>

1. Manual Scenario: <br>
In a manual scenario, you need to manually design the scenario as per the given performance metrics. While designing the scenario, you have to provide the inputs like how many users to run and for how much duration and in what way the Vusers have to be started and ended. Based on the scenario, LoadRunner executes the test. <br>
In order to create a Manual Scenario, select Manual Scenario from “Select Scenario Type” <br>
You can select the scripts you wish to add to the scenario right from the above screen. However, it is generally practiced to add the scripts later. <br>

Click the OK button to proceed. <br>
This will create a blank scenario and load it into the main screen. You will notice the Save button is enabled now. <br> 

Likewise, if you selected Percentage Mode while selecting type of scenario, the screen will appear slightly differently. <br> Instead of number of users, it will show the distribution of users in percentage. Controller distributes users per assigned percentage automatically. <br>
If you do not create a Scenario at the start, you will notice the toolbar as below: <br>

How to use Controller in LoadRunner <br>
  - You can click on How to use Controller in LoadRunner button to create a new blank Scenario. Once a scenario has been - created, you can click on How to use Controller in LoadRunner button to Save a scenario or click Ctrl + S. Likewise, you can -   - click on How to use Controller in LoadRunner button to open an already existing scenario from your local computer drive.

2. Goal-Oriented Scenario: <br>
In the goal-oriented scenario, you have to specify the target, and minimum and maximum no. of Vusers and duration. When the test script execution starts then LoadRunner checks whether the goal or target can be reached or not. If the target is unreachable then it stops the execution. The user load is started from min no. of Vusers to max no. of Vusers. <br> 

The targets can be mentioned in terms of <br>

  - Transaction Response time
  - Virtual Load (User Load)
  - Transactions per second
  - Hits per second
  - Pages per minute <br>  

A Goal-Oriented scenario is dynamic in nature – this means, it keeps changing the overall load being simulated over the server. You set a Goal, for example, the maximum number of hits you wish to achieve for the target server, maximum response time against a transaction etc. <br>  

Based on above numeric, you can draw analytics such as a maximum number of users your application support while staying between acceptable response time. Similarly,The maximum number of users connected to application till X number of hits to the server is reached.<br>  

In such a case, HP Controller automatically varies the number of users to the server, thus, you’ve little control over how many numbers of times or for how long a user runs. <br> 

Click New to create a new scenario and select Goal-Oriented Scenario. <br> 

Process of adding VUser Groups is exactly same as in case of Manual Scenario. <br> 

The key differences in Goal Oriented Scenario, as the name suggests, is to create a goal. The Controller will automatically <br> 

While most of the interface is pretty much similar to Manual Scenario, certain screen appears differently, although perform the same actions. For example, to add a VUser Group or a VUser Script, click on the How to use Controller in LoadRunner ADD SCRIPT button. <br> 

### Day 33: 6 April 2022
## BASICS OF ANALYSIS
What is Analysis? <br>
LoadRunner Analysis is a software that analyses executed tests. LoadRunner Analysis takes the dump in that has been created by the controller during testing. The dump contains raw data that gets processed by LoadRunner Analysis to create different tables and diagrams. <br>  

The last and important phase of Performance Testing Life Cycle is Test Result Analysis and Reporting. LoadRunner also follows the same approach i.e. after completion of the test it generates test result for analysis purpose so that you can compare the result with the defined SLA and also identify the issue if any. To carry out the result analysis part, LoadRunner has a dedicated tool called ‘Analysis’. <br>
Performance test result analysis is the most important and technical part in performance testing rather than scripting and execution. Performance test result analysis requires your actual expertise. During the analysis phase, you can determine bottleneck and remediation options at an appropriate level i.e. business, middleware, application, infrastructure, network etc. <br> 

Analysis tool is really helpful to conduct the analysis on the performance test result. Micro Focus Analysis Tool has multiple graphs and statistics which display the result in a simple, accurate and in-depth form. They help to detect bottleneck and report enabling you to view and understand the data and analyse system performance after a test run.There is a long list of graphs available in the analysis tool. <br>

How to perform test result analysis in LoadRunner? <br>
If you conduct the performance test on LoadRunner Professional then you have to provide the path of the result directory before starting the test. In this result directory, the test result is saved. You can get the path of result directory by following: <br> 

Results -> Result Settings -> Set Results Directory <br>

Browse the location and get the result in .lrr format file. <br> 

Analysis Tool:

- Open ‘Analysis’ tool on your local machine. Install the same if it is not available.
- Goto File -> New
- Navigate to the result file folder (which should contain .lrr file)
- Click ‘Open’
- Test Result Analysis session will open in the Analysis tool.

If you use LoadRunner Enterprise for your test then follow the below step to get result file(s). <br> 

In the navigation toolbar, click the three lines icon and select Test Runs. <br>
Select the performance test you just ran in the test management tree and click the Runs tab. <br>
If the test run is in the ‘Before Collating Results’ state then right-click the run and select ‘Collate’. <br>
LoadRunner Enterprise collates the results for the test run
When result collation has finished and the test run is in the ‘Before Creating Analysis Data’ state then right-click the run and select ‘Analyze’. <br>
When LoadRunner Enterprise has finished analyzing the results then download the Results file in zip format. <br>

### Day 34: 12 April 2022
## STANDARDS REPORTS AND OBSERVATIONS
Performance Test Analysis Report: <br>
Once you complete the analysis then you can publish the result using the reporting option available in the Analysis tool. To use this feature, go to the ‘Reports’ tab and generate the report by using New Report, Report Template, HTML Report etc. options. Once you generate the report you have a large list of the file format to save the report like .doc, .pdf, .xps, .html, .txt, .xls, .csv sand so many different and useful file formats. This saved report along with your analysis and conclusion can be easily shared with the client or project team. <br> 

In the Summary Report tab, you can see the duration of the scenario which was run to get these results. <br>

The term percentile is used in analysis almost with every graph. You can define the value for percentile in the properties panel. The default is set to 90. <br>
Few graphs appearing already. You can click on the graph name and you will see its details appearance. <br> 

From the Summary Report, you can click on the button to open its SLA related information. <br>
All the buttons in the toolbar perform some action from within the File menu. <br> 

Analysis Graphs: <br>
HP Analysis will load most important graphs at the time of Analysis. You can click on any graph name from the Session Explorer to view details against available graph. <br> 
- Average Response Time graph:<br>
This graph displays the number of hits made on the Web server by VUsers during each second of the load test. This graph helps you evaluate the amount of load VUsers generate, in terms of the number of hits.
- Hits Per Second graph: <br>
This graph displays the number of hits made on the Web server by VUsers during each second of the load test. This graph helps you evaluate the amount of load VUsers generate, in terms of the number of hits.
- Running VUsers graph: <br>
This graph displays the number of VUsers that executed VUser scripts, and their status, during each second of a load test. This graph is useful for determining the VUser load on your server at any given moment.
- Throughput graph: <br>
This graph displays the amount of throughput (in bytes) on the Web server during the load test. Throughput represents the amount of data that the VUsers received from the server at any given second. This graph helps you to evaluate the amount of load VUsers generate, in terms of server throughput.
- VUser Summary: <br>
This graph displays the number of VUsers that completed their run successfully, stopped their run, or ended with errors.
- Rendezvous graph: <br>
This graph Indicates when VUsers were released at rendezvous points and how many VUsers were released at each point. 
- Transactions Per Second graph: <br>
This graph displays the number of completed transactions (both successful and unsuccessful) performed during each second of a load test. This graph helps you determine the actual transaction load on your system at any given moment.
- Total Transactions Per Second graph: <br>
This graph displays the total number of completed transactions (both successful and unsuccessful) performed during each second of a load test. This graph helps you determine the actual transaction load on your system at any given moment. 
- Transaction Summary graph: <br>
This graph displays the number of transactions that passed, failed, stopped, or ended with errors.
- Transaction Performance Summary graph: <br>
This graph displays the minimum, average, and maximum response time for all the transactions in the load test.
- Transaction Response Time Under Load graph: <br>
Displays average transaction response times relative to the number of VUsers running at any given point during the load test. This graph helps you view the general impact of VUser load on performance time and is most useful when analyzing a load test which is run with a gradual load. 
- Transaction Response Time Percentile graph: <br>
This graph displays the percentage of transactions that were performed within a given time range. This graph helps you determine the percentage of transactions that meet the performance criteria defined for your system.
- Transaction Response Time Distribution graph: <br>
This graph displays the number of times a transaction was completed over a distribution of time ranges. Note that this graph only displays information for a single transaction at a time.
- Throughput (MB) graph: <br>
This graph displays the amount of throughput (in megabytes) on the Web server during the load test. Throughput represents the amount of data that the VUsers received from the server at any given second. This graph helps you to evaluate the amount of load VUsers generate, in terms of server throughput.
- HTTP Status Code Summary: <br>
This graph displays the distribution of the various HTTP protocol status codes returned from the Web Server during the load test.
- HTTP Response Per Second graph: <br>
This graph displays the number of the different HTTP status codes returned from the Web server during each second of the load test.
- Pages Download Per Second graph: <br>
This graph displays the number of pages received from the Web server during the load test. 
- Connections graph: <br>
This graph displays the number of Connections.
- Connections Per Second graphs: <br>
This graph displays the number of Connections per Second. 
- Page Component Breakdown (Over Time) graph: <br>
This graph displays the average response time (in seconds) for each Web page and its components during each second of the scenario run. <br>  


Add New Graphs: 
- To add new graph, click on the Graph menu and select Add New Graph.
- Once clicked, it will open a list of all graphs available in LoadRunner (HP Analysis)
- You can select any graph by double-clicking on its name. This will load the graph with values/statistics to the main window of HP Analysis.
- Click the Close button to go back to the main window.

Crossing with Results: 
- If you’ve multiple scenario runs already, you can use their results folder to cross match the statistics. This process helps directly compare both results and generate a cumulative report.
- In order to perform Cross results, click onHow to use Analyzer in LoadRunnericon from the toolbar or click Cross with Results from the File Menu.

Saving a Session:
- Working with HP Analysis may take significant time. Since you may have merged graph or currently studying some new graph, it is a good idea to keep your session information saved.
- To save your session, click on the File Menu and click on Save.

Opening a Session:
- You can open an existing session in similar way. Simply click Open under File Menu and select the folder of saved session. Remember, HP Analysis will not open the last folder node; rather it will open the folder itself.

Exporting into HTML Report:
- HP Analysis provides a feature to export all data into a well formatted HTML or doc format report. To export, click on the Report menu and select HTML Report.

what is Hits per second? <br>
‘Hits per second’ refers to the number of HTTP requests sent by the user(s) to the Web server in a second. In terms of performance testing, there is a major difference in Transactions per second and Hits per second. A single transaction can create multiple hits on the server. <br> 

What is throughput? <br>
Throughput represents the amount of data that the VUsers received from the server at any given second. <br> 
 
### Day 35: 13 April 2022
## REHEARSE THE PREVIOUS DAYS

### Day 36: 14 April 2022
## REHEARSE THE PREVIOUS DAYS
 
### Day 37: 18 April 2022
## BASIC OF PT EXECUTION

What is Performance Test Execution? <br>
Performance Test Execution word refers to run the tests specific to performance testing like load test, soak test, stress test, spike test etc. using performance testing tool. Performance Test Plan contains detailed information of all these tests which need to be executed in the performance testing window. Basically, this phase has two sub-phases:

- Test Execution: To run the planned performance tests
- Result Analysis: To analyse the test result and prepare an interim test report
Purpose: <br>
Performance Test execution phase has the following activities to be performed:

- Execute the documented/agreed performance test
- Analyse the performance test result
- Verify the result against defined NFRs
- Prepare an Interim Performance Test Report
- Take the decision to complete or repeat the test cycle based on the interim test result

Approach for Test Execution: <br>
Pre-execution activities: <br>
Before starting the test execution there are few pre-requisite which a performance tester should follow. He must pay attention to the below points: <br>

- Verify all the performance test scripts locally
- Validate all the scenarios
- Check all the external file path in the test script. The file path should match with the file location available at load generator
- Check whether load generator and controller have sufficient disk space
- Reboot the controllers and all the load generators (if feasible)
- All the performance tests should run on the latest code of the application
- The performance test environment should have the QA (functional test) passed version code only so that application is free from any functional bug
- Verify the script on load generator by running a smoke test before starting the actual load test
- Verify all the test data (if feasible) so that there is no failure in the test due to the test data issue
- Restart Web/Application/Database servers before starting a test
- Perform server logs clean-up activity
- Conduct a quick Healthcheck to verify the stability of the environment
- Verify whether all the required monitors are up and running
- Validate the run-time setting and parameter files
- If the test is scheduled then check the system time must be synced with the testing tool time so that test can be started at the correct time.
- After verifying all the check-points, a performance tester can press the ‘Run’ button to start the test.

Test Execution: <br>
Once the test starts then check the graphs and stats in the live monitors of the testing tool. A performance tester needs to pay attention to some basic metrics like active users, transactions per second, hits per second, throughput, error count, error type etc. Also, he needs to check the behaviour of the users against the defined workload. At last, the test should stop properly and the result should be collated correctly at the given location. <br> 

Post-execution activities: <br>
Once a performance test completes then a performance tester collects the result and starts the result analysis which acts as a post-execution activity. A performance tester should follow the below approach to conduct the performance test result analysis. <br>  


Pre-result analysis activities: <br>
Before starting the performance test result analysis, a performance tester should follow these important points:

- The test should run for the defined duration
- Filter-out the ramp-up and ramp-down duration
- Eliminate ‘Think Time’ from the graphs/stats
- Eliminate ‘Pacing’ (if the tool counts) from the graphs/stats
- No tool specific error should occur like the failure of load generator, memory issue etc.
- No network related issue should occur during the test like network failure, LGs become disconnected from network etc.
- The testing tool should collect the results from all the load generators and prepare a combine test report
- CPU and Memory utilization percentage should be noted down for pre-test (at least 1 hour), post-test (at least 1 hour) and during the test.
- Use proper granularity to identify correct peaks and lows
- Use filter option and eliminate the unwanted transactions (if any)
 
Result Analysis: <br>
Start the analysis with some basic metrics like
- Number of Users: The actual load during steady state should meet the user load NFR
- Response Time: The actual response during steady state should meet the response time NFR. The response time should be measured at two levels – Individual transaction response time and end-to-end response time. If NFRs are available for both the levels then they should meet
- Transactions per second / Iterations per hour: If any of these metrics is defined then the actual result should match with the defined figure
- Throughput: Throughput should match (not apple-to-apple) for the same set of tests
- Error: The error count should be less than the defined error tolerance limit
- Passed Transaction counts: Ideally, the passed count of the first transaction should match with the passed count of the last transaction. If it is not the case then identify the failed transactions
- Analyse the graphs:
  - Set the proper granularity for all the graphs
  - Read the graph carefully and note down the points
  - Check the spikes and lows in the graph
  - Merge the different graphs to identify the root cause of the issue
  - If performance testing tool and monitoring tool are not integrated then note the time when the error occurred and sync the graphs generated by both the tools
  - Do not extrapolate the result on the basis of incomplete statistics
 
Analyse the other reports:
  - Generate the heap dump and analyse the Java heap during the test
  - Perform thread dump analyse to check the deadlock or stuck thread
  - Analyse the Garbage Collector logs
  - Analyse the AWR report to find a long time taking DB query.

Post-result analysis activities: <br>
A performance tester gathers all the result i.e. client side and server side stats and starts analysing the result. He verifies the results against the defined NFRs. After each test, performance tester prepares an interim test report which is analysed by a Performance Test Lead or Manager. <br> 

Some key points for reporting:
- It is good practice to generate an individual test report for all the tests
- Define a template for test report and use the same template to generate the report
- Highlight the observations and defects in the test report
- If performance testing tool does not have reporting feature then prepare an interim test report (template link is available in the deliverable section of this post)
- Attach all the relevant reports like heap dump analysis report, AWR report etc. with the interim test report
- Provide defect description along with defect ID
- Conclude the result as Pass or Fail status
- Along with result if a performance tester detects any performance bottleneck then he raises the defect and assigns to the respective team for further investigation on the root cause. The root cause analysis activity is basically a team effort wherein the performance tester, system administrators, technical experts and DBA play a vital role. The test execution and bottleneck analysis activities are cyclic in nature.
 
### Day 38: 19 April 2022
## WORKLOAD CONFIGURATION

What is workload model? <br>
Distribution of load across the identified transactions in a given time is called Workload. Workload helps us to study the behavior of the system under various identified workload model. <br> 

Workload model can be designed by predictability, repeatability and scalability. E.g. consider a website which provides online seasonal greeting cards. During festival seasons, the number of visitors will be high, whereas during non-seasonal time, visitors will be minimal. By predicting the number of visitors, one can design workload model accordingly. <br> 

While designing workload model for banks or financial sector application, once should consider repeatability as well as scalability too. <br> 

Before designing workload model, it is important to collect relevant data which helps us to create effective workload model. Following items are required, in order to design effective workload model. <br>  

Number of concurrent users <br>
Total Transactions to be achieved <br>
Scenario and its Actions <br>
% of total user for an action <br>

Preparing workload model graph: <br>

Usually load testing will be done at least for an hour with 15 minutes of ramp-up and ramp-down period, and the steady state period will be for 1 hour.  <br>
Let me summarize the steps to design workload model: 

- Analyze the application
- Identify the metrics such as transactions, concurrent users etc.
- Design the load distribution
 -Design the workload graph

Important note:<br>
it is not advisable to have steady state during the initial phase; because sudden load to the server may clog the server resources and leads to internal failure. Continuing the load test with such failures gives invalid data for analysis. <br> 

Importance of WLM (Workload Modeling): <br>
Your performance test results will be more accurate if you manage to properly simulate your production system parameters in your test. It’s the planning phase where the performance analyst makes sure that the information of all the parameters of AUT has been acquired in order to accurately simulate them in the performance test. Identifying AUT workload model is one of the most important parts of the planning activity. Workload model provides the information of what type of user actions will be tested under load, what will be the business scenarios for all the users and what will be users’ distribution on every scenario. <br> 

Little's Law in Performance Testing: <br>
Workload modelling is an important part of performance test planning. Accuracy of your workload model result into an accurate performance report. <br> 

Little's Law is a very useful to define the workload model in performance testing.According to the Little's Law: <br>

N=TPS*(RT+TT+PT) <br>

N = No of users (Expected virtual users) <br>

TPS= Transaction per second. ( if you have TPH-Transaction Per Hour value, divide it by 3600 to convert in to TPS). <br>

RT= Total execution time of a script( This include end to end execution time of script without think time and pacing)  <br>

TT= Total Think Time in the script ( Sum of think time between all the transactions)  <br>

PT= Pacing Time ( It is pause time between two iterations, After end of previous iteration and before start of new iteration)  <br> 

Calculating no of users using Little's law: <br>
Suppose we have an application with submit claim workflow. Client has given a requirement that they want to achieve 6000 claim submittion in an hour with think time of 5 seconds between each transaction (suppose we have total 5 transactions in script action including login and logout) and pacing of 10 seconds. Assume that script take 30 seconds to execute without think time and pacing. Calculate no of virtual users to achieve the desired output. <br>

As per the little's law,  <br>
TPS = 6000/3600 = 1.667 <br>
RT= 30 <br>
TT= 20 ( As we have total 5 transactions,  there will be four instances of think time hence 5*4)  <br>
Pacing = 10 <br> 

N = 1.667 * (30+20+10) <br>
N = 1.667 * 60 <br>
N = 100 <br> 

Value of total no of virtual users is 100. <br>

### Day 39: 20 April 2022
## PACING CALCULATION AND CREATING REPORT IN EXCEL

What is Think Time? <br>
Think time in load testing is the time difference between each action of a single user. A user while browsing the application spends some amount of time (think time) before doing some action on the website. For example, on an e-commerce web application, a user clicks on a product tile, goes to its product display page, and then waits there to consume and read the content over this page before clicking on the Add to Cart button. The time spent from clicking on the product tile to clicking on Add to Cart is called think time. The value of think time varies from user to user, but for our test scenario, we can take the average of think time. <br> 


what is pacing? <br>
Pacing is used during load tests to make sure we are running the test with desired transaction per second. It’s the time difference between each complete iteration of business flow. It helps us to control the count of requests sent to the server per second. Pacing is slightly different than think time. As we described above, think time is the delay between actions within iterations or steps. As we have mentioned, load testing is not about hitting the server with as many requests as possible with no delay, the test plan with desired throughput can be achieved by finding the correct value of pacing. Additionally, pacing, along with think time, also helps to better simulate the user’s experience and provides a more realistic load test. There is typically a short period of time between iterations, so it is an important factor to consider when setting up your load tests. <br>

Why it’s Important to Introduce Delays in Load Testing Scenarios? <br> 
Load testing the application before full stage roll-out saves us from a potential bad experience faced by end users with issues, like timeouts, slow page responses, and downtime. In order to get close to realistic load test results and find issues, if any, we would need to bring our test scenario to be as realistic as possible. Consideration of think time and pacing in our test scenario design helps us to test how server’s queuing management, thread utilization, and memory management is behaving under heavy load. For example, if we try adding think time in between each concurrent user action, during this delay the server tends to pick other pending tasks from the queue, executes the next task and then picks the old task again. This step is exactly what happens over production with real users. Adding think time also increases the time spent by the user on the application, which identifies issues related to concurrent user handling capacity of the server. <br> 

Pacing calculation: <br>

For second option- <br>
Pacing = ((3600*users)/TPH(Transactions Per Hour) <br> 

For third option- <br>
Pacing = (3600*users)/TPH(Transactions Per Hour) - (Runtime of one script with think time)<br>

### Day 40: 21 April 2022
## LR ASSESSMENT

### Day 41: 22 April 2022
## INSTALLATION OF JMETER
1. Check if Java Is Installed if not then install java 

2. Download JMeter
- To download JMeter go to the Apache JMeter website <br>
https://jmeter.apache.org/download_jmeter.cgi

3. Install JMeter
- Once the zip folder is downloaded, go to the folder location, and then extract the zip folder
- Once the folder is extracted go inside that folder and then go inside the bin folder here
- In the bin folder open the jmeter.bat file
- It will take a while to open, and this is how you can download and install JMeter onto your system. 

Now when you have installed JMeter, you can execute a test for the same.

### Day 42: 25 April 2022
## JMETER
The Apache JMeter is an open-source, purely Java-based software. The software is used to perform performance testing, functional testing, and load testing of web applications. <br>
It is used to test load testing functional behavior and measuring performance. JMeter makes it possible by creating a huge number of concurrent users that simulate a heavy load. <br>

Test plan elements order of execution <br>
A test plan elements are ordered and executed always in the following way: <br>
1. Configuration nodes
2. Pre processors
3. Timers
4. Sampler
5. Post processors
6. Assertions
7. Listeners <br>
It is good to mention that a test plan can contain one or more test plans inside it <br>
 
TEST PLANS: <br>
Test plans are sets of requests against local or remote servers (or clients) configured to run by following specific instructions. <br>

THREAD GROUP: <br>
A thread group is basically a combination of different test plan elements. It is the root of a test plan and it controls the basic central parameters. <br>
In order to create a test plan you may have to create at first a thread group and configure its number of threads, the ramp-up period, the loop counts and the behavior in case or error:
- Number of threads: The number of threads that are going to be used to execute the test plan, very important to configure load and stress tests.
- Ramp-up period: Time that JMeter will need to start all threads.
- Loop count: Number of iterations, that is the amount of times that the test is going to be executed.

### Day 43: 26 April 2022
## LOGIC CONTROLLERS,SAMPLERS,LISTENERS,TIMERS

LOGIC CONTROLLERS: <br>
Logic controllers are elements that allow you to configure the order of execution of different samplers inside a Thread group. <br>
This list contains all available logic controllers in JMeter:
- Simple Controller
- Loop Controller
- Once Only Controller
- Interleave Controller
- Random Controller
- Random Order Controller
- Throughput Controller
- Runtime Controller
- If Controller
- While Controller
- Switch Controller
- ForEach Controller
- Module Controller
- Include Controller
- Transaction Controller
- Recording Controller <br>
 
SAMPLERS: <br>
Samplers are used for sending requests to different kind of servers. They are the basic element of every test plan and everything works around them: they execute requests (based on the configuration provided) and these requests produce one or more responses that are analyzed afterwards. <br>

LISTENERS: <br>
Listeners provide different ways to view the results produced by a Sampler requests. Listeners parse results in form of tables, trees or plain log files. <br>
 
TIMERS: <br>
You can define the time period that you want to wait between requests using timers. If you do not specify any, JMeter will execute the next request immediately after the current one is finished, without any waiting time. <br>
Following timers are available in JMeter: <br>
- Constant Timer
- Gaussian Random Timer
- Uniform Random Timer
- Constant Throughput Timer
- Synchronizing Timer
- JSR223 Time
- BeanShell Time
- BSF Time
- Poisson Random Time
 
### Day 44: 27 April 2022
## ASSERTIONS,PRE PROCESSORS,POST PROCESSORS
ASSERTIONS: <br>
Assertions confirm the validity of the test plan by validating the response produced by a Sampler request. Basically assertions are similar to unit test assertions and check the quality of the tested application response. <br>
Here is a list of available assertions in JMeter: 
- Bean shell Assertion
- BSF Assertion
- Compare Assertion
- JSR223 Assertion
- Response Assertion
- Duration Assertion
- Size Assertion
- XML Assertion
- BeanShell Assertion
- MD5Hex Assertion
- HTML Assertion
- XPath Assertion
- XML Schema Assertion

PRE PROCESSORS:  <br>
Pre processors are elements (actions, assertions or basically whatever) that is going to happen before a sampler is executed.  <br>
These are the elements that can be used as pre processors:
- HTML Link Parser
- HTTP URL Re-writing Modifier
- HTTP User Parameter Modifier
- User Parameters
- JDBC PreProcessor
- JSR223 PreProcessor
- RegEx User Parameters
- BeanShell PreProcessor
- BSF PreProcessor

POST PROCESSORS:  <br>
Is basically an element that is executed after a sampler execution finishes. It can be used to parse the response data and extract values that can be used afterwards. <br>
These elements can be used as post processors:
- Regular Expression Extractor
- XPath Extractor
- Result Status Action Handler
- JSR223 PostProcessor
- JDBC PostProcessor
- BSF PostProcessor
- CSS/JQuery Extractor
- BeanShell PostProcessor
- Debug PostProcessor
 
### Day 45: 28 April 2022
## JMETER VARIABLES AND FUNCTIONS
JMeter functions are special values that can populate fields of any Sampler or other element in a test tree. <br>
- A function call looks like this − <br>
${__functionName(var1,var2,var3)} <br>
_functionName matches the name of a function. For example ${__threadNum}. <br>
If a function parameter contains a comma, then make sure you escape this with "\" as shown below − <br>
${__time(EEE\, d MMM yyyy)} <br>
- Variables are referenced as − <br>
${VARIABLE} <br>

### Day 46: 29 April 2022
## DOUBT CLARIFICATION SESSION WITH INSTRUCTOR
 
### Day 47: 2 May 2022
## Basics of PT execution

What is Performance Test Execution? <br>
Performance Test Execution word refers to run the tests specific to performance testing like load test, soak test, stress test, spike test etc. using performance testing tool. Performance Test Plan contains detailed information of all these tests which need to be executed in the performance testing window. Basically, this phase has two sub-phases:

- Test Execution: To run the planned performance tests
- Result Analysis: To analyse the test result and prepare an interim test report
Purpose: <br>
Performance Test execution phase has the following activities to be performed: <br>

Execute the documented/agreed performance test <br>
- Analyse the performance test result
- Verify the result against defined NFRs 
- Prepare an Interim Performance Test Report
- Take the decision to complete or repeat the test cycle based on the interim test result

Approach for Test Execution: <br>
Pre-execution activities: <br>
Before starting the test execution there are few pre-requisite which a performance tester should follow. He must pay attention to the below points: <br>

- Verify all the performance test scripts locally
- Validate all the scenarios
- Check all the external file path in the test script. The file path should match with the file location available at load generator
- Check whether load generator and controller have sufficient disk space
- Reboot the controllers and all the load generators (if feasible)
- All the performance tests should run on the latest code of the application
- The performance test environment should have the QA (functional test) passed version code only so that application is free from any functional bug
- Verify the script on load generator by running a smoke test before starting the actual load test
- Verify all the test data (if feasible) so that there is no failure in the test due to the test data issue
- Restart Web/Application/Database servers before starting a test
- Perform server logs clean-up activity
- Conduct a quick Healthcheck to verify the stability of the environment
- Verify whether all the required monitors are up and running
- Validate the run-time setting and parameter files
- If the test is scheduled then check the system time must be synced with the testing tool time so that test can be started at the correct time.
- After verifying all the check-points, a performance tester can press the ‘Run’ button to start the test.

Test Execution: <br>
Once the test starts then check the graphs and stats in the live monitors of the testing tool. A performance tester needs to pay attention to some basic metrics like active users, transactions per second, hits per second, throughput, error count, error type etc. Also, he needs to check the behaviour of the users against the defined workload. At last, the test should stop properly and the result should be collated correctly at the given location. <br> 

Post-execution activities: <br>
Once a performance test completes then a performance tester collects the result and starts the result analysis which acts as a post-execution activity. A performance tester should follow the below approach to conduct the performance test result analysis. <br> 


Pre-result analysis activities: <br>
Before starting the performance test result analysis, a performance tester should follow these important points: <br>

-  test should run for the defined duration
- Filter-out the ramp-up and ramp-down duration
- Eliminate ‘Think Time’ from the graphs/stats
- Eliminate ‘Pacing’ (if the tool counts) from the graphs/stats
- No tool specific error should occur like the failure of load generator, memory issue etc.
- No network related issue should occur during the test like network failure, LGs become disconnected from network etc.
- The testing tool should collect the results from all the load generators and prepare a combine test report
- CPU and Memory utilization percentage should be noted down for pre-test (at least 1 hour), post-test (at least 1 hour) and during the test.
- Use proper granularity to identify correct peaks and lows
- Use filter option and eliminate the unwanted transactions (if any)

Result Analysis: <br>
Start the analysis with some basic metrics like <br>
- Number of Users: The actual load during steady state should meet the user load NFR
- Response Time: The actual response during steady state should meet the response time NFR. The response time should be measured at two levels – Individual transaction response time and end-to-end response time. If NFRs are available for both the levels then they should meet
- Transactions per second / Iterations per hour: If any of these metrics is defined then the actual result should match with the defined figure
- Throughput: Throughput should match (not apple-to-apple) for the same set of tests
- Error: The error count should be less than the defined error tolerance limit
- Passed Transaction counts: Ideally, the passed count of the first transaction should match with the passed count of the last transaction. If it is not the case then identify the failed transactions
Analyse the graphs: 
- Set the proper granularity for all the graphs
- Read the graph carefully and note down the points
- Check the spikes and lows in the graph
- Merge the different graphs to identify the root cause of the issue
- If performance testing tool and monitoring tool are not integrated then note the time when the error occurred and sync the graphs generated by both the tools
- Do not extrapolate the result on the basis of incomplete statistics
Analyse the other reports:
- Generate the heap dump and analyse the Java heap during the test
- Perform thread dump analyse to check the deadlock or stuck thread
- Analyse the Garbage Collector logs
- Analyse the AWR report to find a long time taking DB query.

Post-result analysis activities: <br>
A performance tester gathers all the result i.e. client side and server side stats and starts analysing the result. He verifies the results against the defined NFRs. After each test, performance tester prepares an interim test report which is analysed by a Performance Test Lead or Manager. <br> 

Some key points for reporting:

- It is good practice to generate an individual test report for all the tests
- Define a template for test report and use the same template to generate the report
- Highlight the observations and defects in the test report
- If performance testing tool does not have reporting feature then prepare an interim test report (template link is available in the deliverable section of this post)
- Attach all the relevant reports like heap dump analysis report, AWR report etc. with the interim test report
- Provide defect description along with defect ID
- Conclude the result as Pass or Fail status
- Along with result if a performance tester detects any performance bottleneck then he raises the defect and assigns to the respective team for further investigation on the root cause. The root cause analysis activity is basically a team effort wherein the performance tester, system administrators, technical experts and DBA play a vital role. The test execution and bottleneck analysis activities are cyclic in nature.

### Day 48: 4 May 2022
## Terminologies in Jmeter:-
- Test Plan
- ThreadGroup
- Samplers
- Listeners
- WorkBench
- Assertions
- Config Element
- Logic Controllers
- Timer

a)Test Plan <br>
Just as a simple test plan in Software Testing consists of all steps which execute the script, JMeter’s Test plan has the same purpose. Everything which is included in a test plan is executed in a sequence which is top to bottom or as per the defined sequence in the test plan. <br>

Test Plan can be as simple as it could be, with Just ThreadGroup, Sampler, and Listener and it starts getting more complex as soon as you start adding more elements like config elements, preprocessors or controllers.<br>

As we all know that JMeter measure performance by generating Virtual Users or Threads which hits server under test as if real users are sending requests to a server. Therefore, every Test Plan should have virtual users or Thread Group as we call them in JMeter’s terms. <br>

Important Points about Test Plan:

- The test plan should be saved before running
- Jmeter files or test plans are saved in form of. JMX extension files
- You can also save parts of Test Plan as the different selection. For example, If you want to save HTTP Request Sampler with Listener, you can save it as Test -  - - - Fragment so that it can be used in other test scenarios as well
- Elements of WorkBench are not saved with Test Plan.

b)Thread Group <br>
Thread Group is a group of users which will be hitting the server under test either concurrently or in some predefined sequence. Thread Group can be added to Test Plan by right clicking the test plan. JMeter is all “Right Click stuff”, you get all the options on the right click. <br>
You can rename Thread Group name to your own. Just change the name and click anywhere outside the Test Plan window, you would see the name getting changed.
It is very important to configure your thread group as per the test conditions. <br> 

Basically, there are three main parameters which must be configured to generate actual load or virtual users: <br>

Number of Thread(Users) – It defines the number of virtual users. For testing purpose, we should generate only a limited amount of load as generating huge volume at once would mean consuming lot many threads which can ultimately lead to high CPU utilization. <br>
Ramp Up Period – This field is very important in controlling the load generation. Ramp up period defined the amount of time in which the total load will be generated. <br> 

c)Samplers <br>
Loop Count – It defines the number of times Thread Group will execute. If you check the Forever check box your test will run forever unless you manually stop it. This can be used to test something like “If your server doesn’t crash on continuous load for few minutes”. <br>
So, how does a Jmeter knows what type of request has been sent to server??? <br> 

It is through Samplers. Samplers are a must to add to a Test Plan as only it can let Jmeter know what type of request need to go to which server and with any predefined parameters or not. Requests could be HTTP, HTTP(s), FTP, TCP, SMTP, SOAP etc. <br>
Samplers can only be added to Thread Group not directly under Test Plan as Thread Groups need to use a sampler to send a request to server URL under test. The sampler can be added by path Thread Group -> Sampler -> HTTP Request. <br>  

HTTP Requests- <br>
These are the most common requests sent to the servers. <br> 

FTP Requests- <br>
Path-> Test Plan-> Thread Group-> Sampler-> FTP Request <br> 

FTP stands for File Transfer Protocol and it is used to upload or download a file from the server. JMeter’s threads send requests to FTP servers to upload or download files from there and measures the performance. <br> 

d)Listeners <br>
Listeners are used to display the results of test execution so that testers get to know the stats. We have around 15 listeners in Jmeter but mostly used ones are table, tree, and Graph. <br> 

View Results in Table:<br> 

This is the most commonly used and easily understandable form of listeners. It displays the result in form of table with some important performance parameters. <br>

View Results in Tree: <br> 

This is another most commonly used listeners and provides detailed information with request and response. One can also view the HTML page rendered in response apart from viewing Json, XML, Text, RegEx. <br> 

e)Work Bench <br>
A workbench is a place where you can store those elements which are not in use in your current test plan but which can be later copy pasted in it. When you save JMeter file, the components which are present in workbench are not automatically saved. You must save them separately by right clicking and choose “Save as “option. <br>

The reason of having workbench was that user could do some experiments and try out new scenarios. As we already know elements in workbench are not saved so a user can literally use anything and then throw away. But, there are some “Non-Test Components” which are only available in WorkBench. <br>

They are listed here: <br> 

- HTTP Mirror Server
- HTTP(s) Test Script Recorder
- Property Display
- HTTP(s) Test Script Recorder is the most important Non-Test Element used in JMeter. It helps testers in recording the script and then configuring the load for each transaction.

Jmeter only records the request sent to the server. Don’t get confused with “Record and Play” functionality of QTP/Selenium.  All the requests are recorded and testers can apply the desired load on them to see the behavior. <br> 

f)Assertions <br>
Till now, we have covered how JMeter hits the server and how the responses are displayed via listeners. To ensure that the response received is correct and as per expectation, we need to add assertions. Assertions are simply validations which we need to put on responses to compare the results. <br> 

Below are the types of assertions commonly used: <br> 

- Response Assertion
- Duration Assertion
- Size Assertion
- XML Assertion
- HTML Assertion

Response Assertion:- <br>
In Response Assertion, we can add our own pattern strings and then compare them with the responses received from a server. <br> 

Duration Assertion:- <br>
Duration Assertion is very important and validates that the server responded within a given amount of time. This can be used in scenarios where we need to sample 100 requests and ensure that every time response is received within the benchmarked limit.<br>

g)Config Elements <br>
Requests sent to the server can be further parameterize using some config elements which are executed before the actual request. A simple example of it could be reading values of a variable from a CSV file for which CSV Data Set Config is used.<br> 

Below are some of the important config elements used in the performance testing of the web and mobile applications

- CSV Data Set Config.
- User Defined Variables
- HTTPS Requests Default
- HTTPS Cache Manager
- HTTPS Cookie Manager

CSV Data Set Config: <br>
CSV data set config helps Jmeter in picking values of some parameters from a CSV file rather than passing different parameter in each separate request. For example, if we need to test login functionality with a different set of users and passwords, then we can create two columns in a CSV file and enter the values there so that JMeter can pick one for each request sent to the server. <br> 

User Defined Variables:<br>
It helps Jmeter to pick values from a pre-defined variable. For example, support that you need to create a test plan in which you need to add many HTTP requests on the same URL and there could be a scenario in which client plans to migrate it later to some different URL.So, to avoid updating URL in each request we can tell JMeter to pick the URL from a UDV (User Defined Variable) which can be later updated to handle all requests to updated URL<br>  

HTTP Request Defaults:<br>
This config element is very useful for specifying the default values of https requests.  To guide you more, take an example where we need to hit 50 different requests at google server.In this scenario, if we add an HTTP Request Default then we need not specify a server name, path or any other properties like port number, connection time out properties. Whatever is specified in the HTTP Request Default config element is inherited by all HTTP requests.<br>  

HTTP Cache Manager and HTTP Cookie Manager are used in making JMeter behave as a real-time browser. HTTP Cache manager can clear cache after each request whereas the other one can manage the cookies settings.<br>
 
### Day 49: 5 May 2022
## DOUBT CLARIFICATION SESSION WITH INSTRUCTOR 
 
### Day 50: 6 May 2022
## JMETER MASTER-SLAVE CONFIGURATION 

Assuming one master and one slave needs to be configured for distributed JMeter testing. Therefore, assuming following are the IP’s of the two machines. <br>
Machine A — (Master Machine) IP = 172.16.222.26 <br>
Machine B — (Slave Machine) IP = 172.16.222.87 <br>
Make sure that both machines have same version of JMeter and JDK installed. Also, make sure that the environment system variable (e.g. “JMETER_HOME = D:\apache-jmeter-5.1.1”) is set on both the machine respectively. <br>
1. On the machine A, go the JMeter bin directory. Open the “jmeter. Properties” file and provide salve (machine-B) IP as mentioned in the screen shot shown below: <br>
2. Now, run the “create-rmi-keystore” batch file on the machine-A (master), located in Jmeter bin directory. Here, in the console window, we need to provide the values like name, company, country etc. <br>  
For username and password, please provide following values: <br>
name: rmi & password: changeit <br>
3. On the completion of this step, the console window would closed and we would see “rmi_keystore” file being created in master machine-A JMeter bin directory. <br>
4. Now copy this file (rmi_keystore file) and placed it on the Slave machine-B JMeter bin directory. <br>
5. On the master machine-A, run the batch file “jmeter-server” as mentioned below: <br>
After above step, go to machine-B (slave) > JMeter bin directory and run “jmeter-server” batch file. This console window would open and master slave connection would be established. <br>
6. From the machine-A (master), we need to run the script mentioning “. jmx” script as well result logging location along with slave machine IP. Given below is an example command line run at the master machine-A. <br>

jmeter -n -t “D:\JMeterScript.jmx” -l “D:\apache-jmeter-5.1.1\JmeterResultsCSV\results.csv” -R 172.16.222.87  <br> 

PACING:  <br>
Pacing in load testing refers to the time between the iterations of your test scenarios. This is unlike Think Time, which refers to the delay between actions or interactions inside iterations.By using pacing in your test, you will be able to regulate the rate of requests that hit your application and accurately achieve a desired load <br>

### Day 51:  9 May 2022
## Smoke Testing
Smoke Testing is a software testing process that determines whether the deployed software build is stable or not. Smoke testing is a confirmation for QA team to proceed with further software testing. It consists of a minimal set of tests run on each build to test software functionalities. Smoke testing is also known as “Build Verification Testing” or “Confidence Testing.” <br>

How to Do a Smoke Test <br>
The process to implement an automated smoke test will vary depending on your application and the configuration of your build tool. But the basic steps of smoke testing should remain the same. <br>

1. Prepare for Testing.  <br>
After you've completed the build successfully — and before you test your application — you may need to perform setup steps. This might include copying files to the appropriate places, setting up database tables, installing licenses, or starting a server. <br>

2. Get Your Test Files. <br>
Your next step is to gather the files required for your smoke test. If you're using smoke testing software from Perforce, you would use the command line to fetch several smoke test files to the local drive. <br>

3. Write a Script. <br>
Using a single script for smoke testing will give you more flexibility (while keeping the build script static). Your smoke test should run run from your build tool. Once it has run, its report should be saved with the rest of the build files. If something fails, it needs to be reported to the developers (along with an output of the script). <br>
If you're using smoke testing software from Perforce, your script would be similar to: "C:Program FilesSeapineQA Wizard ProQAWRunScript.exe" "SmokeTestSmokeTest.qawwspace" "SmokeTestSmokeTest.qawscript" /Reportfile "BuildCurrentReport.qawreport" <br>

4. Clean Up. <br> 
After the smoke test, you need to clean up. This might include stopping a server, deleting files, or emptying database tables. This could also be done before the initial setup step to ensure that the environment is clean before any tests are started.<br>
 
h)Logic Controllers And Timers
Logic controllers and timers help Jmeter control the flow of transactions. Timers ensure the delay in each thread if need to test any server. For Example, if we need FTP request to wait for 5 secs after HTTP request is completed, we can add timer there.

Logic Controllers are used to defining the flow of requests which are sent to the server. It can also let you store requests for each module separately such as login and logout.

### Day 52:  10 May 2022
## LR AND JMETER REVISION SESSIONS
  
### Day 53 - 58: 11 May 2022 - 18 May 2022
## PROJECT DELIVERABLES
  
### DAY 59: 19 May 2022
##  Coding Challenge1 (CC1)  JMETER
  
### DAY 60: 20 May 2022
##  Coding Challenge2 (CC2)  JMETER
  
### DAY 61: 21 May 2022
##  Coding Challenge3 (CC3)  JMETER
  
### DAY 62: 22 May 2022
##  Coding Challenge4 (CC4)  JMETER
  
### DAY 63: 25 May 2022
##  Integrated Capability Test(ICT)  JMETER

  

                                                                                                                    
          
